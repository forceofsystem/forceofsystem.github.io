<!DOCTYPE html>
<html lang="zh-cn">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">

  
  <meta name="author" content="Patrick">

  
  
  <meta name="description" content="我校的计算机组成原理课的正式名字为：计算机组成原理与体系结构，然而讲授的内容却更多偏向组成原理，体系结构的部分只是讲了最简单的流水线部分的知识。所以我在大二时买了《计算机组成与设计——软件硬件接口》的 MIPS 版打算学习，只读了指令和编码的部分。上个学期又买了 RISC-V 版，也没有来得及看，正好最近在做 GCC RISC-V 后端的工作，自觉在阅读《Computer Architecture: A Quantitive Approach》前应该读一读这本书，便索性画了 3 天连读带写，将书中的内容写成一份博客分享出来。">
  

  
  <link rel="icon" href="https://forceoflife.cn/favicon.jpeg">

  
  
  <meta name="keywords" content=" hugo  latex  theme ">
  

  
  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css"
  integrity="sha384-KiWOvVjnN8qwAZbuQyWDIbfCLFhLXNETzBQjA/92pIowpC0d2O3nppDGQVgwd2nB" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
  integrity="sha384-0fdwu/T/EQMsQlrHCCHoH10pkPLlKA1jL5dFyUOvB3lfeT2540/2g6YgSi2BL14p" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js"
  integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: '$$', right: '$$', display: true },
        { left: '\\[', right: '\\]', display: true },
        { left: '$', right: '$', display: false },
        { left: '\\(', right: '\\)', display: false }
      ],
      ignoredTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code', 'option'],
      throwOnError: false
    });
  });
</script>


  

  
  <meta property="og:url" content="https://forceoflife.cn/zh-cn/post/jsjzcysjsy/">
  <meta property="og:site_name" content="生活之力">
  <meta property="og:title" content="计算机组成拾遗--CPU 如何更快地运行程序？">
  <meta property="og:description" content="我校的计算机组成原理课的正式名字为：计算机组成原理与体系结构，然而讲授的内容却更多偏向组成原理，体系结构的部分只是讲了最简单的流水线部分的知识。所以我在大二时买了《计算机组成与设计——软件硬件接口》的 MIPS 版打算学习，只读了指令和编码的部分。上个学期又买了 RISC-V 版，也没有来得及看，正好最近在做 GCC RISC-V 后端的工作，自觉在阅读《Computer Architecture: A Quantitive Approach》前应该读一读这本书，便索性画了 3 天连读带写，将书中的内容写成一份博客分享出来。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-06-28T21:50:46+08:00">
    <meta property="article:modified_time" content="2024-06-28T21:50:46+08:00">
    <meta property="article:tag" content="计算机体系结构">
    <meta property="article:tag" content="计算机">


  
  <link rel="canonical" href="https://forceoflife.cn/zh-cn/post/jsjzcysjsy/">

  
  
  
  <meta itemprop="name" content="计算机组成拾遗--CPU 如何更快地运行程序？">
  <meta itemprop="description" content="我校的计算机组成原理课的正式名字为：计算机组成原理与体系结构，然而讲授的内容却更多偏向组成原理，体系结构的部分只是讲了最简单的流水线部分的知识。所以我在大二时买了《计算机组成与设计——软件硬件接口》的 MIPS 版打算学习，只读了指令和编码的部分。上个学期又买了 RISC-V 版，也没有来得及看，正好最近在做 GCC RISC-V 后端的工作，自觉在阅读《Computer Architecture: A Quantitive Approach》前应该读一读这本书，便索性画了 3 天连读带写，将书中的内容写成一份博客分享出来。">
  <meta itemprop="datePublished" content="2024-06-28T21:50:46+08:00">
  <meta itemprop="dateModified" content="2024-06-28T21:50:46+08:00">
  <meta itemprop="wordCount" content="9739">
  <meta itemprop="keywords" content="计算机体系结构,计算机">

  
  <link media="screen" rel="stylesheet" href='https://forceoflife.cn/css/common.css'>
  <link media="screen" rel="stylesheet" href='https://forceoflife.cn/css/content.css'>

  
  
  <title>计算机组成拾遗--CPU 如何更快地运行程序？ - 生活之力</title>
  

  
  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="计算机组成拾遗--CPU 如何更快地运行程序？">
  <meta name="twitter:description" content="我校的计算机组成原理课的正式名字为：计算机组成原理与体系结构，然而讲授的内容却更多偏向组成原理，体系结构的部分只是讲了最简单的流水线部分的知识。所以我在大二时买了《计算机组成与设计——软件硬件接口》的 MIPS 版打算学习，只读了指令和编码的部分。上个学期又买了 RISC-V 版，也没有来得及看，正好最近在做 GCC RISC-V 后端的工作，自觉在阅读《Computer Architecture: A Quantitive Approach》前应该读一读这本书，便索性画了 3 天连读带写，将书中的内容写成一份博客分享出来。">


  
<link rel="stylesheet" href='https://forceoflife.cn/css/single.css'>

</head>

<body>
  <div id="wrapper">
    <header id="header">
  <h1>
    <a class="head" href="https://forceoflife.cn/">生活之力</a>
  </h1>

  <nav>
    
    <span class="nav-bar-item">
      <a class="head" href="/zh-cn/">主页</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="head" href="/zh-cn/post/">博客</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="head" href="/zh-cn/about/">关于我</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="head" href="/zh-cn/index.xml">订阅</a>
    </span>
    
    <span class="nav-bar-item">
      <a class="head" href="/en">EN</a>
    </span>
    
  </nav>
</header>

    
<main id="main" class="post">
  
  
  <h1>计算机组成拾遗--CPU 如何更快地运行程序？</h1>
  
  <div>
    
    <a class="link keywords" href='https://forceoflife.cn/zh-cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84'>#计算机体系结构</a>
    
    <a class="link keywords" href='https://forceoflife.cn/zh-cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA'>#计算机</a>
    
  </div>
  
  
  
  <details>
    <summary class="toctext">
        <b>Table of Contents</b>
    </summary>
    <div class="toc"><nav id="TableOfContents">
  <ul>
    <li><a href="#1-如何度量计算机的性能">1. 如何度量计算机的性能</a></li>
    <li><a href="#2-程序可以比想象快流水线">2. 程序可以比想象快：流水线</a>
      <ul>
        <li><a href="#21-流水线冒险">2.1 流水线冒险</a></li>
      </ul>
    </li>
    <li><a href="#3-流水线背后指令级并行">3. 流水线背后——指令级并行</a>
      <ul>
        <li><a href="#31-静态多发射">3.1 静态多发射</a></li>
        <li><a href="#32-动态多发射处理器">3.2 动态多发射处理器</a></li>
        <li><a href="#33-多发射存在的问题">3.3 多发射存在的问题</a></li>
      </ul>
    </li>
    <li><a href="#4-程序还能更快并行">4 程序还能更快：并行</a>
      <ul>
        <li><a href="#41-并发与并行的区别">4.1 并发与并行的区别</a></li>
        <li><a href="#42-创建并行处理程序的难点">4.2 创建并行处理程序的难点</a></li>
        <li><a href="#43-并行硬件分类和向量机">4.3 并行硬件分类和向量机</a></li>
      </ul>
    </li>
    <li><a href="#5-结语">5. 结语</a></li>
  </ul>
</nav></div>
  </details>
  
  
  <article class="content">
    
    <p>我校的计算机组成原理课的正式名字为：计算机组成原理与体系结构，然而讲授的内容却更多偏向组成原理，体系结构的部分只是讲了最简单的流水线部分的知识。所以我在大二时买了《计算机组成与设计——软件硬件接口》的 MIPS 版打算学习，只读了指令和编码的部分。上个学期又买了 RISC-V 版，也没有来得及看，正好最近在做 GCC RISC-V 后端的工作，自觉在阅读《Computer Architecture: A Quantitive Approach》前应该读一读这本书，便索性画了 3 天连读带写，将书中的内容写成一份博客分享出来。</p>
<blockquote>
<p>中文译版质量太低，我怀疑是老师手底下的英语没过六级的研究生用 Word 翻译的QAQ。</p>
</blockquote>
<h2 id="1-如何度量计算机的性能">1. 如何度量计算机的性能</h2>
<p>要想让程序运行得快，最简单的方式就是买一台更好、更快的计算机，可如何比较不同计算机的速度呢？你可能认为，只需要计算出程序运行花费了多少秒，或者多少微秒然后比大小就可以了。但我们的目的是要让计算机上运行的程序跑得更快，这种粗粒度的比较方式并不能给我们提供什么有用的信息，所以我们必须要找到一种更具有参考价值的度量方法。</p>
<p>一般而言，计算机通过时钟来确定各类事件在硬件中何时发生，这些离散的时间间隔被称为时钟周期数，也就是一个时钟周期的长度。我们还可以使用时钟周期的倒数——时钟频率（如 4 GHZ）。</p>
<p>我们通常用如下方法来统计程序的 （CPU）执行时间：</p>
<p>$$程序的\ CPU\ 执行时间 = 程序的\ CPU\ 时钟周期数  \times 时钟周期长度$$</p>
<p>进一步地，拥有了程序的 CPU 时钟周期数，我们就能以此来计算指令的性能：</p>
<p>$$CPU\ 时钟周期数 = 程序的指令数 \times 指令平均周期数$$</p>
<p>指令平均周期数（clock cycle per instruction）表示执行每条指令所需的时钟周期平均数，缩写为 <strong>CPI</strong>，这也是我们度量计算机性能的主要指标，我们正是用它来比较不同处理器的性能。</p>
<h2 id="2-程序可以比想象快流水线">2. 程序可以比想象快：流水线</h2>
<img src="https://cdn.jsdelivr.net/gh/zzxdyf1314/mycloudimg@master/image-20240628223216681.png" alt="计算机的组成部件" style="zoom:50%;" />
<p>我们可以把计算机认为是一个工厂，我们将原材料送进工厂，工厂给我们提供我们想要的产品，而计算机这个工厂的工人就是 CPU。如何让工厂能够更高效地生产呢，让我们回忆一下在初中历史课本上学到了什么。没错，我猜你和我一样想到了福特，就是福特汽车的创始人——亨利·福特，就是他在汽车制造的工厂中引入了流水线，从而获得了商业上的巨大成功。那我们能不能在计算机这个工厂中引入流水线，让 CPU 像福特公司的工人一样工作呢？</p>
<p>当然可以。</p>
<p>流水线的核心理念是把任务划分成多个步骤，某一个生产单位只负责一个步骤的工作，从而提高生产效率。我们同样可以将处理器也分为多个步骤，例如，常见的 RISC-V 指令的执行过程通常包括以下几步：</p>
<ol>
<li>从存储器中取出指令。</li>
<li>读取寄存器并译码。</li>
<li>执行操作或计算地址。</li>
<li>访问数据存储器中的操作数（如有必要）。</li>
<li>将结果写入寄存器（如有必要）。</li>
</ol>
<p>当我们将 CPU 执行指令的过程分成上面五步后，显然我们会有这样一个流水线：</p>
<img src="https://cdn.jsdelivr.net/gh/zzxdyf1314/mycloudimg@master/image-20240628224814773.png" alt="image-20240628224814773" style="zoom:50%;" />
<p>流水线带来的性能提升可以归结为一个公式：</p>
<p>$$指令执行时间_{流水线} = \frac{指令执行时间_{非流水线}}{流水线级数}$$</p>
<p><strong>理想条件下，流水线带来的加速比约等于流水线级数。</strong></p>
<p>为了更好地利用流水线，我们可以在设计指令集时加入一些额外的设计，比如 RISC-V：</p>
<ol>
<li>所有指令长度相同。</li>
<li>只有几种指令格式，源寄存器和目标寄存器字段的位置相同。</li>
<li>存储器操作数只出现在 load 和 store 指令中。</li>
</ol>
<p>虽然流水线能带来很棒的性能提升，但它并非是没有代价的（又有什么是不付出代价就能得到的呢），这种代价就被称为——冒险（hazard）。</p>
<h3 id="21-流水线冒险">2.1 流水线冒险</h3>
<p>冒险是指下一条指令在下一个时钟周期中无法执行的情况。冒险共分为三种：结构冒险、数据冒险和控制冒险。</p>
<ul>
<li>
<p>结构冒险：硬件不支持多条指令在同一周期执行。</p>
</li>
<li>
<p>数据冒险（流水线数据冒险）：无法提供指令执行所需数据而导致指令不能在预期的时钟周期内执行。</p>
<pre tabindex="0"><code class="language-assembly" data-lang="assembly">add x19, x0, x1
sub x2, x19, x3
</code></pre><ul>
<li>
<p>解决方法（前递或旁路）：向内部资源添加额外的硬件以找到缺少的运算项，使得不需要等待指令完成就尝试解决数据冒险。</p>
</li>
<li>
<p>载入-使用型数据冒险：当载入指令要取的数据还没取回时，其他指令就需要该数据。</p>
<ul>
<li>解决方法：流水线停顿（pipeline stall），俗称 bubble。</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-asm" data-lang="asm"><span style="display:flex;"><span><span style="color:#fabd2f">lw</span>  <span style="color:#d3869b">x1</span>, <span style="color:#d3869b">0</span>(<span style="color:#d3869b">x31</span>)
</span></span><span style="display:flex;"><span><span style="color:#fabd2f">lw</span>  <span style="color:#d3869b">x2</span>, <span style="color:#d3869b">8</span>(<span style="color:#d3869b">x31</span>)
</span></span><span style="display:flex;"><span><span style="color:#fabd2f">add</span> <span style="color:#d3869b">x3</span>, <span style="color:#d3869b">x1</span>, <span style="color:#d3869b">x2</span>
</span></span><span style="display:flex;"><span><span style="color:#fabd2f">sw</span>  <span style="color:#d3869b">x3</span>, <span style="color:#d3869b">24</span>(<span style="color:#d3869b">x31</span>)
</span></span><span style="display:flex;"><span><span style="color:#fabd2f">lw</span>  <span style="color:#d3869b">x4</span>, <span style="color:#d3869b">16</span>(<span style="color:#d3869b">x31</span>)
</span></span><span style="display:flex;"><span><span style="color:#fabd2f">add</span> <span style="color:#d3869b">x5</span>, <span style="color:#d3869b">x1</span>, <span style="color:#d3869b">x4</span>
</span></span><span style="display:flex;"><span><span style="color:#fabd2f">sw</span>  <span style="color:#d3869b">x5</span>, <span style="color:#d3869b">32</span>(<span style="color:#d3869b">x31</span>)
</span></span></code></pre></div><p>将 <code>lw x4, 16(x31)</code> 移到第三行可以消除两个 <code>add</code> 指令对其前一条 <code>lw</code> 指令的依赖导致的冒险。</p>
</li>
</ul>
</li>
<li>
<p>控制冒险（分支冒险）：取到的指令不是需要的，或指令地址的流向不是流水线所预期的，导致正确的指令无法在正确的时钟周期内执行。</p>
<ul>
<li>解决方法：
<ul>
<li>停顿：等待。</li>
<li>预测：预测分支的结果并沿预测方向执行，而不是等分支结果确定后才开始执行。成熟的分支预测是预测一些条件分支指令发生跳转，另一些不发生。当预测错误时，流水线控制必须确保预测错误的条件分支指令之后的指令执行不会生效，并且从正确的分支地址处重新启动流水线。</li>
</ul>
</li>
<li>动态硬件预测器：根据每个条件分支的行为进行预测，结果在生命周期内可能改变。
<ul>
<li>常见实现方法：保存每个条件分支是否发生分支的历史记录根据最近的行为来预测未来。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>流水线级数之所以能够让程序跑得更快，是因为它挖掘了顺序指令流中的<strong class=chinese>指令级并行性</strong>，相对于多处理器编程，流水线的优点在于它对程序员是不可见的，换句话说，程序员无须操心是否能利用好流水线，这是编译器开发者需要费心的（没错，就是我QAQ……）。那么指令级并行性是什么呢？</p>
<h2 id="3-流水线背后指令级并行">3. 流水线背后——指令级并行</h2>
<p>指令级并行性（Instruction Level Parallelism，简称ILP）是指在计算机体系结构中，处理器能够同时执行多条没有数据依赖关系的指令的能力。</p>
<p>有两种常见的提高指令级并行度的方法：</p>
<ul>
<li>
<p>增加流水线级数，使更多的指令重叠执行。</p>
</li>
<li>
<p>多发射（multiple issue）：增加流水线内部的功能部件数量，使每周期发出多条指令。</p>
<blockquote>
<p>目前高端处理器的发射宽度为每周期 3 - 6 条指令，普通处理器的发射宽度一般为 2。</p>
</blockquote>
</li>
<li>
<p>推测：编译器或处理器“猜测”指令的行为，以尽早消除掉该指令与其他指令之间的依赖关系，可以由编译器实现（code schedule）或是由处理器硬件在动态执行时完成相同的操作，当推测错误时，需要将处理器恢复到推测前的状态。</p>
<p>例如：</p>
<ul>
<li>预测分支结果，提早执行分支后的指令；</li>
<li>对于先 <code>store</code> 再 <code>load</code> 的指令，可以预测两条指令访问的地址不同，同时提早执行 <code>load</code>。</li>
</ul>
<p>推测的问题也很明显：</p>
<ul>
<li>实现推测错误时的恢复机制比较困难；</li>
<li>对某条指令的推测可能引入不必要的例外。</li>
</ul>
</li>
</ul>
<p>增加流水线级数是一种很明显的方法，由于有更多的操作可以重叠执行，指令间的并行性自然更高。</p>
<p>我们主要来看第二种方法，多发射。根据指令发射与否的判断所在的阶段可以将多发射分为两种：</p>
<ul>
<li>静态多发射：编译时判断</li>
<li>动态多发射：动态执行过程中由硬件完成</li>
</ul>
<h3 id="31-静态多发射">3.1 静态多发射</h3>
<p>静态多发射处理器可以将同一周期发射出的指令集合（issue packet）看成一条需要进行多种操作的“大指令”。</p>
<blockquote>
<p>静态多发射处理器通常会对同一周期发射的指令类型进行限制。将发射指令包看成一条预先定义好、需要进行多种操作的指令，这符合超长指令字（Very Long Instruction Word，VLIW）的设计思路。</p>
</blockquote>
<p>静态多发射由编译器来支持指令打包和处理冒险，编译器的任务主要有两个：</p>
<ul>
<li>静态分支预测</li>
<li>代码调度</li>
</ul>
<p>静态单发射处理器（尤其是超长指令字处理器）中，通常对同时发射的指令组合进行限制：</p>
<ul>
<li>指令需要成对</li>
<li>指令地址需要 64 位对齐</li>
<li>ALU 指令和分支指令放在前面</li>
<li>如果指令对中的一条指令无法发射，需将其替换为 <code>nop</code> 指令。</li>
</ul>
<p>静态单发射处理器解决冒险主要有两种方式：</p>
<ul>
<li>编译器全部解决</li>
<li>使用硬件来检测两个指令包间的数据冒险并产生相应的流水线停顿；编译器只负责解决单个指令包中的类型问题。</li>
</ul>
<p>如果想同时发射 ALU 和数据传输指令，需要添加硬件以读写寄存器堆。因为 ALU 指令需要读取两个寄存器，store 指令可能需要读取两个以上的源寄存器；ALU 指令和 load 指令都需要更新一个目标寄存器，而 ALU 部件只负责计算 ALU 指令的执行，所以还需要额外增加一个加法器来进行地址的计算从而避免大量的结构冒险。</p>
<blockquote>
<p>利用多发射以提高程序运行的例子：循环展开。</p>
<ul>
<li>反相关：由于名称服用而导致的顺序排列，并不是真正的数据相关（真相关）。</li>
</ul>
</blockquote>
<h3 id="32-动态多发射处理器">3.2 动态多发射处理器</h3>
<ul>
<li>动态多发射处理器也称为超标量处理器或朴素的超标处理器，能够在硬件层面判断当前周期可以发射的指令数。</li>
<li>超标量是一种高级流水线级数，指处理器能够在动态执行时选择指令，并在一个周期内执行一条以上的指令。</li>
</ul>
<p><strong>与超长指令字处理器的区别：不论是否需要编译器参与，超标量处理器都需要在硬件层面保证程序的正确性。</strong></p>
<p>许多超标量处理器扩展了动态发射逻辑，演变为动态流水线调度技术：一种为避免停顿而对指令执行顺序进行重排的硬件技术。</p>
<p>在基于动态流水线调度的处理器中，流水线被分为三个部分：</p>
<ul>
<li>取指和发射单元：取指令、译码、将指令发送到各自的功能单元。</li>
<li>多功能部件（高端处理器中数量多达十几个）：执行指令，将结果保存到提交单元。每一个功能单元都有若干保留站，用来存放指令的操作和所需的操作数。当指令所需的操作数和功能单元都就绪时，就可以执行指令，执行结果会被传送给保留站中正在等待使用该结果的指令，同时也传送到提交单元中进行保存。</li>
<li>提交单元：保存已完成的指令的执行结果，在指令真正提交时用它们更新寄存器或写入内存。
<ul>
<li>提交单元的缓冲区被称为 <strong>reorder buffer</strong>。</li>
</ul>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/zzxdyf1314/mycloudimg@master/image-20240629162618560.png" alt="image-20240629162618560" style="zoom:50%;" />
<blockquote>
<p>动态多发射处理器通过在保留站中保留操作数以及在重排序缓冲中保存运算结果，提供了一种类似寄存器重命名的技术：</p>
<ol>
<li>发射指令时，指令会被拷贝到相应功能单元的保留站中，如果指令所需的操作数已准备好，也会从寄存器堆或者重排序缓冲中拷贝到保留站。对于处在发射阶段的指令，由于可用操作数都保存在保留站中，其在寄存器堆中的副本就没必要保存了，如果有操作需要堆该寄存器执行写操作，那么该寄存器的值就会被更新。</li>
<li>如果操作数不在寄存器堆或者重排序缓冲中，那它一定在等待某个计算单元的计算结果，此时该计算单元的名字会被记录。当最终结果计算完毕后，将不会保存到寄存器堆，而是直接从功能单元拷贝到对应保留站中。</li>
</ol>
<p>通过这种类似寄存器命名的技术，处理器可以在不违背程序原有数据流顺序的前提下以某种顺序执行指令，即<strong class=chinese>乱序执行</strong>。</p>
</blockquote>
<p>虽然在执行阶段，指令可以乱序执行，但为了保证程序行为和简单的按序单发射流水线一致，乱序执行流水线的取指和译码都需要按序进行，以便正确处理指令间的相关。提交阶段也需要按照取指的顺序依次将指令执行的结果写入寄存器和存储中，这种保守的处理方法被称为<strong class=chinese>按序提交</strong>。这样的好处是发生例外时处理器很容易就能找到例外前的最后一条指令，保证只更新这条指令之前的指令所写的寄存器。</p>
<blockquote>
<p>更高级的动态调度技术还包括基于硬件的推测式执行，尤其是基于分支预测的推测式执行。通过预测分支指令的转移方向来沿着预测路径不间断地取指和执行指令。这种方法的好处是在提交时，基于按序提交的提交单元可以保证在提交预测路径上的指令结果前就得知是否预测正确。这种方法还支持推测 <code>load</code> 指令访问的地址。</p>
</blockquote>
<p>乱序执行会产生一些新的流水线冒险：</p>
<ul>
<li>Write-After-Read（WAR） 冒险</li>
<li>Write-After-Write（WAW）冒险</li>
<li>Read-After-Write（RAW）冒险</li>
</ul>
<p>相比于只用编译器通过指令调度来解决数据相关的问题，超标量处理器使用基于硬件实现的动态调度技术有以下几点优势：</p>
<ol>
<li>不是所有的流水线停顿都是可预测的，特别是由于缓存失效带来的停顿就无法被预测到。</li>
<li>只使用推测式执行技术去挖掘程序的指令级并行性会影响推测式执行的结果，例如频繁出现的例外。</li>
<li>不同的流水线实现具有不同的延迟和发射宽度，动态调度技术可以隐藏这部分细节从而降低编译器的开发难度。</li>
</ol>
<h3 id="33-多发射存在的问题">3.3 多发射存在的问题</h3>
<p>虽然现代处理器可以通过多发射提高性能，但是保持高发射率是非常困难的。尽管存在四发射或六发射的处理器，但应用很难保持两条以上的发射率，原因主要有两点：</p>
<ul>
<li>指令之间的依赖关系造成了流水线内部的性能瓶颈。很多时候这种依赖关系并不是真相关而是由于编译器和硬件的能力有限，如 C 语言中使用的指针，会产生存储器别名导致潜在的数据相关。也因此衍生出了静态分析中的别名分析（Alias Analysis）技术。</li>
<li>存储层次中的缓存失效会使得流水线不能满负荷运转。</li>
</ul>
<p>在挖掘了指令级并行性后，程序即使运行在一个处理器上也可以以一个可观的速度运行。那如何让程序更快呢？我们需要更多的处理器！</p>
<h2 id="4-程序还能更快并行">4 程序还能更快：并行</h2>
<h3 id="41-并发与并行的区别">4.1 并发与并行的区别</h3>
<p>并发（current）和并行（parallel）一直是一个容易混淆的概念，其原因是两者的表现形式都是多个任务同时被执行。并发的反面是顺序，而并行的反面是串行。我们通常会使用操作系统来作为并发程序的例子，操作系统是一组进程互相写作来处理多个任务，因为操作系统是并发程序，所以可以在进程之间不断切换从而执行不同的任务，如果一个操作系统是顺序程序，那么就必须执行完一个任务再执行另一个任务；并发并不需要有多个处理器，它可以通过调度来制造拥有多个处理器的假象。而并行则不然，并行是指有多个处理器来完成任务，可以是任务级并行也可以是并行处理程序。</p>
<blockquote>
<p>任务级并行：多个处理器完成多个独立的任务，也称为进程级并行。</p>
<p>并行处理程序：多个处理器完成一个任务。</p>
</blockquote>
<p>可以用一张表格来区分并发、顺序、并行和串行：</p>
<p><img alt="并行与并发" src="https://cdn.jsdelivr.net/gh/zzxdyf1314/mycloudimg@master/image-20240629182117366.png"></p>
<h3 id="42-创建并行处理程序的难点">4.2 创建并行处理程序的难点</h3>
<p>并行性的挑战在于，只有很少的应用程序能在被重写后在多处理器上更快地完成任务，因为很难利用多处理器来加速单个任务的运行，尤其是当处理器的数量增多时。造成这个问题主要有两个原因：</p>
<ol>
<li>多处理器上运行的并行处理程序必须获得更好的性能或更高的能效，而单处理器技术（如超标量和乱序执行）都充分利用了指令级并行，减少了多处理器重写程序的需求。</li>
<li>处理器的增多，意味着需要将任务划分为更多可并行的部分、保证工作之间的负载均衡，解决更复杂的调度问题，尽可能减小同步时间并减小各部分间通信的开销。</li>
</ol>
<p>对于第二个原因，我们还可以进一步考虑其影响因素：</p>
<p>首先来复习一下 Amdahl 定律：</p>
<p>$$优化后的时间 = \frac{受优化影响的执行时间}{优化量} + 不受优化影响的执行时间$$</p>
<p>我们可以基于 Amdahl 定律给出加速比上的 Amdahl 定律：</p>
<p>$$加速比 = \frac{改进前的执行时间}{改进前的执行时间 - 受优化影响的执行时间 + \frac{受优化影响的执行时间}{优化量}}$$</p>
<p>为了进一步阐释这个公式，我们需要进行一些简单的计算：</p>
<blockquote>
<p>Q：如果想在 100 个处理器上实现 90 倍的加速，那么原始计算中可以顺序执行的比例是多少？</p>
<p>A：假设改进前的执行时间在某个单位时间内为 1，并且受优化影响的执行时间可以被视作与原始执行时间的比值，则有</p>
<p>$$加速比 = \frac{1}{(1 - 受优化影响的执行时间比例) + \frac{受优化影响的执行时间比例}{优化量}}$$</p>
<p>将优化量带入有：</p>
<p>$$90 = \frac{1}{(1 - 受优化影响的执行时间比例) + \frac{受优化影响的执行时间比例}{100}}$$</p>
<p>简化公式有：</p>
<p>$$受优化影响的执行时间比例 = 89 / 89.1 = 0.999$$</p>
<p>即为了在 100 个处理器上实现 90 倍的加速，顺序执行的程序部分最多占 0.1%。</p>
</blockquote>
<p>也就是说，如果一个程序想要充分利用很多核心，即使是该程序的很小一部分也需要进行改写，不幸的是有大量的应用程序都具有固有的并行性，也就是说我们想要改写程序有很大的工作量。为了了解这些固有的并行性从哪里来，我们不妨再进行一些简单的计算：</p>
<blockquote>
<p>Q：对于如下两个加法：</p>
<ul>
<li>对 10 个标量变量的求和；</li>
<li>一对 $10 \times 10$ 的二维数组求和；</li>
</ul>
<p>若只有矩阵求和可以并行话，则使用 10 个和 40 个处理器能达到的加速比是多少？如果矩阵维数变为 $20 \times 20$ 呢？</p>
<p>A：假设性能是加法程序所需时间 t 的函数，则加法程序在单个处理器上的运行时间是 110t，那么由 Amdahl 定律这个加法程序在 10 个处理器上的执行时间为：</p>
<p>$$优化后的时间 = \frac{受优化影响的执行时间}{优化量} + 不受优化影响的执行时间 = \frac{100t}{10} + 10t = 20t$$</p>
<p>则加速比为 5.5。</p>
<p>在 40 个处理器上的执行时间为：</p>
<p>$$优化后的时间 = \frac{受优化影响的执行时间}{优化量} + 不受优化影响的执行时间 = \frac{100t}{40} + 10t = 12.5t$$</p>
<p>加速比为 8.8。</p>
<p>在这个规模下，在 10 个处理器上获得了潜在加速比的大约 55%，在 40 个处理器上获得了潜在加速比的 22%。</p>
<p>在矩阵规模增加后，响应的数据为 82% 和 51%。</p>
</blockquote>
<p>上面的计算告诉我们，保持问题规模不变的情况下在多处理器上获得良好的加速比相比于将问题规模放大的情况是更难的，因此为了区分这两种情况，我们引入了如下的两个定义：</p>
<ul>
<li>强比例缩放（strong scaling）：</li>
<li>弱比例缩放（weak scaling）：</li>
</ul>
<p>容易想到，扩大问题规模会使处理器使用更多的内存，由此带来的缓存失效可能会干扰弱比例缩放的优势。</p>
<blockquote>
<p>通常来说，我们要根据应用程序的不同来选择不同的缩放方式。</p>
</blockquote>
<p>最后，我们来看负载均衡对于加速比的影响：</p>
<blockquote>
<p>Q：在上面的例子中，如果负载最重的处理器完成两倍负载（5%）和五倍负载（12.5%）时的加速比是多少，其他处理器的利用率如何？</p>
<p>A：一个处理器需要完成 5% 的并行负载，则它要执行 $5% \times 400 = 20$ 次加法，另外的 39 个处理器将平分剩余的 380 次，由于计算是同时进行的，我们只需要计算两者时间的最大值：</p>
<p>$$优化后的执行时间 = max(\frac{350t}{39},\frac{20t}{1}) + 10t = 30t$$</p>
<p>加速比变为 14，其余 39 个处理器的使用时间不到负载最重的处理器的一半。</p>
<p>同理，对于 12.5% 的负载，对应的加速比为 7，其余处理器的时间不到 20%。</p>
</blockquote>
<p>上面的计算证明了在编写并行程序时保证负载均衡的重要性。</p>
<h3 id="43-并行硬件分类和向量机">4.3 并行硬件分类和向量机</h3>
<h4 id="431-向量与标量">4.3.1 向量与标量</h4>
<p>回忆一下我们在数学中学习过的标量和向量，<strong>标量（Scalar）<strong>只有大小，而向量既有大小又有方向。在计算机体系结构中，标量处理指的是对单个数据项进行操作。标量处理器是顺序操作的，即一次只处理一个数据元素，每次操作针对一个值；而向量处理则是同时对多个数据元素进行操作。在向量处理器中，一条指令可以应用于一组数据，这组数据就被称为</strong>向量（Vector）</strong>。</p>
<h4 id="432-并行硬件分类">4.3.2 并行硬件分类</h4>
<p>在引入向量这个概念后，我们就可以分类并行硬件了，下面介绍的这种并行硬件分类方法自上世纪 60 年代提出后到今天仍在使用，该分类基于指令流数量和数据流数量。</p>
<p><img alt="传统并行分类" src="https://cdn.jsdelivr.net/gh/zzxdyf1314/mycloudimg@master/image-20240629224026828.png"></p>
<p>传统的单处理器具有单个指令流和单个数据流（即 SISD），传统的多处理器具有多个指令流和多个数据流（即 MIMD）。</p>
<blockquote>
<p>在 MIMD 计算机上编程时，通常会编写一个运行在 MIMD 计算机中所有处理器的程序，不同处理器通过条件语句来执行对应的代码，这种风格称为<strong class=chinese>单程序多数据流</strong>（Single Program Multiple Data，<strong>SPMD</strong>）。</p>
</blockquote>
<p>通常，我们更喜欢 SIMD，即单指令流多数据流。SIMD 计算机对数据向量进行操作，如单个 SIMD 指令将 64 个数据流发送到 64 个 ALU 上以在单周期内完成 64 次加法来将 64 个数字相加。</p>
<p>SIMD 的优点：</p>
<ul>
<li>SIMD 计算机中所有的并行执行单元都是同步的，响应自同一程序计数器中发出的同一指令。尽管每个单元执行的指令是相同的，但是每个执行单元都有自己的地址寄存器，因此每个单元可以有自己的数据地址。</li>
<li>减少了指令带宽和空间——SIMD 只需要各个处理器同时执行的代码的一个副本，消息传递类型的 MIMD 计算机可能需要在每个处理器中保存一个副本，而共享内存类型的 MIMD 计算机需要多个指令缓存。</li>
</ul>
<p>SIMD 在处理 for 循环中的数组时效果最好，在处理 switch 时效果最差。因此，为了在 SIMD 计算机上并行运行，程序中必须存在大量相同数据结构的数据，即<strong>数据级并行（data-level parallelism）</strong>。</p>
<h4 id="433-向量体系结构">4.3.3 向量体系结构</h4>
<p>向量体系结构的基本原理是从内存中手机数据元，将它们按顺序放入一大组寄存器（向量寄存器）中，使用流水化的执行单元在寄存器中对它们依次操作，将结果写回内存。</p>
<p>下面我们来看一个向量体系结构并行的例子：</p>
<p>DAXPY 是一个在数值计算和线性代数中常用的 BLAS 函数，它的全称是Double precision A times X Plus Y。DAXPY的主要功能是执行向量的线性组合，即计算一个向量与另一个向量的标量乘积再加到第三个向量上。数学上，对于两个实数向量x和y以及一个标量a，DAXPY执行以下操作：</p>
<p>$$Y = a \times X + Y$$</p>
<p>其中 X 和 Y 是 64 个双精度浮点数的向量，最初存储在内存中，a 是一个标量双精度变量。假设 X 和 Y 的起始地址分别存放在 x19 和  X20 ，传统的 RISC-V 代码为：</p>
<pre tabindex="0"><code class="language-assembly" data-lang="assembly">      fld		 f0, a(x3)     // 加载标量 a
      addi	 x5, x19, 512  // 计算数组 X 的边界，作为控制循环结束的条件
loop: fld		 f1, 0(x19)    // 加载 x[i]
      fmul.d f1, f1, f0    // 计算 a * x[i]
      fld		 f2, 0(x20)    // 加载 y[i]
      fadd.d f2, f2, f1    // 计算 a * x[i] + y[i]
      fsd    f2, 0(x20)    // 将结果保存到 y[i] 中
      addi	 x19, x19, 8   // 索引变量 x 自增
      addi	 x20, x20, 8   // 索引变量 y 自增
      bltu   x19, x5, loop // 继续循环
</code></pre><p>假设向量的单个元素长度是 64 位，我们可以写出如下基于 V 扩展的 RISC-V 代码：</p>
<pre tabindex="0"><code class="language-assembly" data-lang="assembly">fld      f0, a(x3)   # 加载标量 a
vsetvli  x0, x0, e64 # 设置 64 位宽的元素
vle.v 	 v0, 0(x19)  # 加载向量 x
vfmul.vf v0, v0, f0  # 向量-标量乘法 a * x[i]
vle.v 	 v1, 0(x20)  # 加载向量 y
vfadd.vv v1, v1, v0  # 向量加法，计算a * x[i] + y[i]
vse.v    v1, 0(x20)  # 将结果存储到 y 中
</code></pre><p>相比之下，向量处理器大大降低了指令带宽，相比于传统 RISC-V 体系结构的 500 条指令，向量 RISC-V 只需要 6 条指令就完成了任务。此外，向量处理器还降低了出现流水线冒险的频率，传统的 RISC-V 代码流水线停顿频率是向量版本的 64 倍，编译器可以使用循环展开来消除这种差异，但仍无法减少指令带宽的巨大差异。</p>
<h4 id="433-硬件多线程">4.3.3 硬件多线程</h4>
<p>硬件多线程与 MIMD 相关，MIMD 依赖于多个进程或线程来使多个处理器保持忙碌状态，而硬件多线程允许多个线程以重叠的方式共享单个处理器的功能单元以有效利用硬件资源。</p>
<ul>
<li>处理器必须复制每个线程的独立状态，如寄存器堆和程序计数器的独立副本。</li>
<li>硬件需要具有在线程之间快速切换的能力。</li>
</ul>
<p>硬件多线程的实现方法：</p>
<ul>
<li>细粒度多线程：在每条指令执行后切换线程（不包括在停顿的线程），从而达成多线程的交叉执行。
<ul>
<li>优点：可以隐藏由短期和长期停顿引起的吞吐量损失。</li>
<li>缺点：减慢单个线程的执行速度。</li>
</ul>
</li>
<li>粗粒度多线程：仅在高开销的停顿上切换线程，如末级 cache 失效时。
<ul>
<li>优点：几乎不会减慢单个线程的执行速度。</li>
<li>缺点：降低吞吐量的能力有限，特别是对于短停顿。因为粗粒度多线程处理器从单个线程发出指令，所以当停顿时必须清空或冻结流水线，新线程必须在造成停顿的指令完成前填充流水线，从而造成了流水线启动开销，当停顿较短时这种开销相对较大。</li>
</ul>
</li>
</ul>
<p>由于多发射处理器中具有大多数单线程难以充分利用的并行功能单元，所以衍生出了一种硬件多线程的变体，称为同时多线程（Simultaneous Multithreading, SMT），它使用多发射、动态调度流水线的处理器资源来挖掘线程级并行和指令级并行。通过寄存器重命名和动态调度技术，处理器可以不需要考虑依赖关系，发射多条来自相互独立线程的多条指令，通过动态调度来解决相关性的问题。</p>
<h4 id="435-多核和其他共享内存多处理器">4.3.5 多核和其他共享内存多处理器</h4>
<p>硬件多线程用很小的代价提升了处理器效率，但我们仍需要想办法有效利用单个芯片上不断增长的处理器核数量来发挥出摩尔定律呈现出的性能潜力。</p>
<p>上文提到，重写就程序使其在并行硬件上高效运行是苦难的，所以我们可以尝试从计算机设计上来降低对应的难度。目前有两种主流的方法：</p>
<ul>
<li>为所有处理器提供一个共享的统一物理地址空间，使得程序无需考虑数据的存放位置，只需要考虑如何并行执行。</li>
<li>为每个处理器采用独立的地址空间，但是在处理器间显式共享地址空间（硬件通常提供 cache 一致性以保证共享内存的一致性）。</li>
</ul>
<p>基于第一种方法，共享内存多处理器（Shared Memory Processor，SMP）为所有处理器提供统一物理地址空间，处理器通过存储器中的共享变量进行通信，所有处理器都能通过 <code>load</code> 和 <code>store</code> 指令访问存储器的任意位置。</p>
<img src="https://cdn.jsdelivr.net/gh/zzxdyf1314/mycloudimg@master/image-20240630004009431.png" alt="共享内存多处理器" style="zoom:50%;" />
<blockquote>
<p>处理器仍可在自己的虚拟地址空间中独立运行程序。</p>
</blockquote>
<p>单地址空间处理器有两种类型：</p>
<ul>
<li>统一内存访问（UMA）多处理器：访问内存的延迟不依赖于提出请求的处理器。</li>
<li>非统一内存访问（NUMA）多处理器：通过划分主存储器并分配给不同的处理器或同一芯片上的不同内存控制器，一些存储器的访问会比其他存储器快，这取决于处理器和其访问的存储器。</li>
</ul>
<blockquote>
<p>在 NUMA 多处理器上编写并行程序的难度更高，但 NUMA 机器更容易扩大到更大规模，同时处理器访问附近的内存时比平均延迟更低。</p>
</blockquote>
<p>处理器并行执行时通常需要共享数据，因此在操作共享数据时需要及时同步，也即需要一套独立的同步机制，通常而言是为共享变量提供锁。</p>
<p>常用的共享内存多处理器编程模型是 OpenMP，它是一套支持共享内存多处理的 API，提供可以对标准编程语言进行扩展的编译器制导、环境变量和运行时库。但 OpenMP 的能力有限，所以也存在很多比 OpenMP 更复杂的并行编程系统。</p>
<blockquote>
<p>MIMD 的另一常见硬件为 GPU，本文不作介绍。</p>
</blockquote>
<h2 id="5-结语">5. 结语</h2>
<p>通过不断地挖掘潜在的并行性，从指令级并行到真正的硬件级并行，CPU 让我们的程序运行得越来越快，而 GPU，特别是 GPGPU 和 DSA（Domain Specific Architect）似乎代表着未来的发展方向。如今，GPGPU 推动着人工智能行业迅猛发展，不知道未来的体系结构又会发生怎样的变化，让我们拭目以待吧。</p>
<blockquote>
<p>希望我能参与其中 QAQ。</p>
</blockquote>
    
  </article>
  <div class="paginator">
    
    <a class="link" href="https://forceoflife.cn/zh-cn/post/wlyh5/">← prev</a>
    
    
    <a></a>
    
  </div>
  <div class="comment">
    
    
    
    
      
    
    
    
  </div>
  
</main>

    <footer id="footer">
  <div class="footcontent">
    <span>© 2023</span> - <span>2024</span>
  </div>

  <div class="footcontent">
    <span>Powered by </span>
    <a class="footlink" href="https://gohugo.io/">Hugo</a>
    <span> 🍦 Theme </span>
    <a class="footlink" href="https://github.com/forceofsystem/hugo-theme-texify">TeXify</a>
  </div>

  <div class="footnote">
    <span>Follow me on <a class=link href=https://github.com/forceofsystem>GitHub</a> |
<a class=link href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh target=_blank rel=noopener>CC BY-NC-SA 4.0</a>
</span>
  </div>
</footer>

  </div>

  
  

  
  

  
  
  
    
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-TZC1QJP9DV"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-TZC1QJP9DV');
        }
      </script>
    
  



</body>

</html>
